{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Magic Storage cooler than you think! Magic storage is a Python library that provides tools to easily write, read and delete resources for testing. This applies, of course, to resources that are difficult to obtain but not very expensive to store locally and, in addition, do not change. A good example are responses from REST APIs or at least those of them that are not live data. The library consists of a set of classes that implement storage using the file system and temporary storage in RAM. All tools can be accessed through the MagicStorage class. Installing # Install and update using pip: 1 $ pip install -U magic_storage Example # 1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from magic_storage import MagicStorage def very_expensive_get () -> Any : ... response = ( MagicStorage () . filesystem ( __file__ ) . cache_if_missing ( \"Nice thing\" , lambda : very_expensive_get ()) ) Documentation # Online documentation is available on Github pages .","title":"Introduction"},{"location":"#installing","text":"Install and update using pip: 1 $ pip install -U magic_storage","title":"Installing"},{"location":"#example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 from typing import Any from magic_storage import MagicStorage def very_expensive_get () -> Any : ... response = ( MagicStorage () . filesystem ( __file__ ) . cache_if_missing ( \"Nice thing\" , lambda : very_expensive_get ()) )","title":"Example"},{"location":"#documentation","text":"Online documentation is available on Github pages .","title":"Documentation"},{"location":"changelog/","text":"Changelog # All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [1.0.0] - 2022-07-03 # Added ReaderBase class specifying reader interface for resource managers. Added WriterBase class specifying reader interface for resource managers.","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#100-2022-07-03","text":"Added ReaderBase class specifying reader interface for resource managers. Added WriterBase class specifying reader interface for resource managers.","title":"[1.0.0] - 2022-07-03"},{"location":"license/","text":"MIT License Copyright (c) 2022 Krzysztof Wi\u015bniewski Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"reference/atomic_file/","text":"File like object supporting writing and reading in quasi atomic manor. All reading and writing is done under lock and writing is done with temporary files and os.replace(). Example # 1 2 3 4 5 6 7 8 9 >>> tmp = getfixture(\"tmp_path\") >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.write_text(\"Example content\") ... >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.read_text() ... 'Example content' >>> Source code in magic_storage/_atomic_file.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 class AtomicFile : \"\"\"File like object supporting writing and reading in quasi atomic manor. All reading and writing is done under lock and writing is done with temporary files and os.replace(). Example ------- ``` >>> tmp = getfixture(\"tmp_path\") >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.write_text(\"Example content\") ... >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.read_text() ... 'Example content' >>> ``` \"\"\" def __init__ ( self , file_path : str | Path ) -> None : file_path = Path ( file_path ) self . _file = file_path . absolute () self . _lock_file = ( file_path . parent / f \" { file_path . name } .lock\" ) . absolute () self . _lock = FileLock ( self . _lock_file ) def __enter__ ( self ) -> AtomicFile : self . _file . touch ( 0o777 , True ) logging . debug ( f \"Created { self . _file } .\" ) self . _lock . acquire () logging . debug ( f \"Acquired { self . _lock_file } .\" ) return self def read_text ( self , ** kwargs : Any ) -> str : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_text() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_text ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value def write_text ( self , content : str , encoding : str = \"utf-8\" , errors : str = \"strict\" , ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. encoding : str, optional Encoding to use, by default \"utf-8\" errors : str, optional Error mode, same rules as for open(), by default \"strict\" \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wt\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , encoding = encoding , errors = errors , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote text to { self . _file } .\" ) def read_bytes ( self , ** kwargs : Any ) -> bytes : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_bytes() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_bytes ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value def write_bytes ( self , content : bytes ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wb\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote bytes to { self . _file } .\" ) def __exit__ ( self , _exception_type : Optional [ Type [ BaseException ]], _exception_value : Optional [ BaseException ], _traceback : Traceback , ) -> None : self . _lock . release () logging . debug ( f \"Released { self . _lock_file } .\" ) read_bytes ( ** kwargs ) # Read data from file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default **kwargs Any Keyword arguments passed to Path.read_bytes() {} Returns: Type Description str data from file. Source code in magic_storage/_atomic_file.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def read_bytes ( self , ** kwargs : Any ) -> bytes : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_bytes() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_bytes ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value read_text ( ** kwargs ) # Read data from file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default **kwargs Any Keyword arguments passed to Path.read_text() {} Returns: Type Description str data from file. Source code in magic_storage/_atomic_file.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def read_text ( self , ** kwargs : Any ) -> str : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_text() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_text ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value write_bytes ( content ) # Write data to file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default content str Content to be saved. required Source code in magic_storage/_atomic_file.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def write_bytes ( self , content : bytes ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wb\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote bytes to { self . _file } .\" ) write_text ( content , encoding = 'utf-8' , errors = 'strict' ) # Write data to file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default content str Content to be saved. required encoding str , optional Encoding to use, by default \"utf-8\" 'utf-8' errors str , optional Error mode, same rules as for open(), by default \"strict\" 'strict' Source code in magic_storage/_atomic_file.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def write_text ( self , content : str , encoding : str = \"utf-8\" , errors : str = \"strict\" , ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. encoding : str, optional Encoding to use, by default \"utf-8\" errors : str, optional Error mode, same rules as for open(), by default \"strict\" \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wt\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , encoding = encoding , errors = errors , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote text to { self . _file } .\" )","title":"AtomicFile"},{"location":"reference/atomic_file/#magic_storage.AtomicFile--example","text":"1 2 3 4 5 6 7 8 9 >>> tmp = getfixture(\"tmp_path\") >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.write_text(\"Example content\") ... >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.read_text() ... 'Example content' >>> Source code in magic_storage/_atomic_file.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 class AtomicFile : \"\"\"File like object supporting writing and reading in quasi atomic manor. All reading and writing is done under lock and writing is done with temporary files and os.replace(). Example ------- ``` >>> tmp = getfixture(\"tmp_path\") >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.write_text(\"Example content\") ... >>> with AtomicFile(tmp / \"some_file.txt\") as file: ... file.read_text() ... 'Example content' >>> ``` \"\"\" def __init__ ( self , file_path : str | Path ) -> None : file_path = Path ( file_path ) self . _file = file_path . absolute () self . _lock_file = ( file_path . parent / f \" { file_path . name } .lock\" ) . absolute () self . _lock = FileLock ( self . _lock_file ) def __enter__ ( self ) -> AtomicFile : self . _file . touch ( 0o777 , True ) logging . debug ( f \"Created { self . _file } .\" ) self . _lock . acquire () logging . debug ( f \"Acquired { self . _lock_file } .\" ) return self def read_text ( self , ** kwargs : Any ) -> str : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_text() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_text ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value def write_text ( self , content : str , encoding : str = \"utf-8\" , errors : str = \"strict\" , ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. encoding : str, optional Encoding to use, by default \"utf-8\" errors : str, optional Error mode, same rules as for open(), by default \"strict\" \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wt\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , encoding = encoding , errors = errors , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote text to { self . _file } .\" ) def read_bytes ( self , ** kwargs : Any ) -> bytes : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_bytes() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_bytes ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value def write_bytes ( self , content : bytes ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wb\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote bytes to { self . _file } .\" ) def __exit__ ( self , _exception_type : Optional [ Type [ BaseException ]], _exception_value : Optional [ BaseException ], _traceback : Traceback , ) -> None : self . _lock . release () logging . debug ( f \"Released { self . _lock_file } .\" )","title":"Example"},{"location":"reference/atomic_file/#magic_storage._atomic_file.AtomicFile.read_bytes","text":"Read data from file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default **kwargs Any Keyword arguments passed to Path.read_bytes() {} Returns: Type Description str data from file. Source code in magic_storage/_atomic_file.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 def read_bytes ( self , ** kwargs : Any ) -> bytes : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_bytes() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_bytes ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value","title":"read_bytes()"},{"location":"reference/atomic_file/#magic_storage._atomic_file.AtomicFile.read_text","text":"Read data from file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default **kwargs Any Keyword arguments passed to Path.read_text() {} Returns: Type Description str data from file. Source code in magic_storage/_atomic_file.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 def read_text ( self , ** kwargs : Any ) -> str : \"\"\"Read data from file. Requires lock to be acquired with context manager. Parameters ---------- **kwargs Keyword arguments passed to Path.read_text() Returns ------- str data from file. \"\"\" assert self . _lock . is_locked value = self . _file . read_text ( ** kwargs ) logging . debug ( f \"Read text to { self . _file } .\" ) return value","title":"read_text()"},{"location":"reference/atomic_file/#magic_storage._atomic_file.AtomicFile.write_bytes","text":"Write data to file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default content str Content to be saved. required Source code in magic_storage/_atomic_file.py 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 def write_bytes ( self , content : bytes ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wb\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote bytes to { self . _file } .\" )","title":"write_bytes()"},{"location":"reference/atomic_file/#magic_storage._atomic_file.AtomicFile.write_text","text":"Write data to file. Requires lock to be acquired with context manager. Parameters: Name Type Description Default content str Content to be saved. required encoding str , optional Encoding to use, by default \"utf-8\" 'utf-8' errors str , optional Error mode, same rules as for open(), by default \"strict\" 'strict' Source code in magic_storage/_atomic_file.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 def write_text ( self , content : str , encoding : str = \"utf-8\" , errors : str = \"strict\" , ) -> None : \"\"\"Write data to file. Requires lock to be acquired with context manager. Parameters ---------- content : str Content to be saved. encoding : str, optional Encoding to use, by default \"utf-8\" errors : str, optional Error mode, same rules as for open(), by default \"strict\" \"\"\" assert self . _lock . is_locked temp = tempfile . NamedTemporaryFile ( mode = \"wt\" , delete = False , suffix = self . _file . name , dir = self . _file . parent , encoding = encoding , errors = errors , ) temp . write ( content ) temp . flush () temp . close () os . replace ( temp . name , self . _file ) logging . debug ( f \"Wrote text to { self . _file } .\" )","title":"write_text()"},{"location":"reference/deleter_base/","text":"Bases: ABC Source code in magic_storage/base/_deleter.py 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 class DeleterBase ( ABC ): def delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : \"\"\"Delete object with specified uid. Attempt to delete non-existing object KeyError will be raised unless missing_ok=True. Parameters ---------- __uid : str object unique identifier. missing_ok : bool, optional ignores missing key errors, by default False \"\"\" uid = make_uid ( __uid ) try : self . _delete ( uid , missing_ok = missing_ok ) except Exception as e : if not missing_ok : raise KeyError ( f \"Couldn't delete { __uid } .\" ) from e @abstractmethod def _delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : ... delete ( __uid , / , * , missing_ok = False ) # Delete object with specified uid. Attempt to delete non-existing object KeyError will be raised unless missing_ok=True. Parameters: Name Type Description Default __uid str object unique identifier. required missing_ok bool , optional ignores missing key errors, by default False False Source code in magic_storage/base/_deleter.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : \"\"\"Delete object with specified uid. Attempt to delete non-existing object KeyError will be raised unless missing_ok=True. Parameters ---------- __uid : str object unique identifier. missing_ok : bool, optional ignores missing key errors, by default False \"\"\" uid = make_uid ( __uid ) try : self . _delete ( uid , missing_ok = missing_ok ) except Exception as e : if not missing_ok : raise KeyError ( f \"Couldn't delete { __uid } .\" ) from e","title":"DeleterBase"},{"location":"reference/deleter_base/#magic_storage.base._deleter.DeleterBase.delete","text":"Delete object with specified uid. Attempt to delete non-existing object KeyError will be raised unless missing_ok=True. Parameters: Name Type Description Default __uid str object unique identifier. required missing_ok bool , optional ignores missing key errors, by default False False Source code in magic_storage/base/_deleter.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 def delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : \"\"\"Delete object with specified uid. Attempt to delete non-existing object KeyError will be raised unless missing_ok=True. Parameters ---------- __uid : str object unique identifier. missing_ok : bool, optional ignores missing key errors, by default False \"\"\" uid = make_uid ( __uid ) try : self . _delete ( uid , missing_ok = missing_ok ) except Exception as e : if not missing_ok : raise KeyError ( f \"Couldn't delete { __uid } .\" ) from e","title":"delete()"},{"location":"reference/filesystem_storage/","text":"Bases: StorageIOBase , FullyFeaturedMixin Implementation of storage class which operates on filesystem items to preserve saved items between sessions. Loading procedures can optionally use caching, they do by default, therefore without disabling it you can't rely on loads being always instantly up to date with stores. Encoding used to read text files, as well as cache can be changed using .configure() method. Parameters: Name Type Description Default __root str | Path root dir for fs storage, if __root points to file, parent directory of this file will be used. required subdir Optional [ str ], optional nested directory to use for file storage, when None, data will be stored directly in __root, by default \"data\". When __root is file, subdirectory in __root parent directory will be used. 'data' Example # 1 2 3 4 5 6 7 8 9 10 11 12 >>> tmp = getfixture('tmp_path') >>> from magic_storage import StoreType >>> fs = FilesystemStorage(tmp) >>> example_item = {\"foo\": 32} >>> UID = \"EXAMPLE UID\" >>> fs.store_as(StoreType.JSON, uid=UID, item=example_item) '4c9e95de851b875493ba6c6dfb16b6aaae5c3e167aef9ab6edfeb0dbca2f6574' >>> fs.is_available(UID) True >>> fs.load_as(StoreType.JSON, uid=UID) {'foo': 32} >>> Source code in magic_storage/impl/_filesystem.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class FilesystemStorage ( StorageIOBase , FullyFeaturedMixin ): \"\"\"Implementation of storage class which operates on filesystem items to preserve saved items between sessions. Loading procedures can optionally use caching, they do by default, therefore without disabling it you can't rely on loads being always instantly up to date with stores. Encoding used to read text files, as well as cache can be changed using .configure() method. Parameters ---------- __root : str | Path root dir for fs storage, if __root points to file, parent directory of this file will be used. subdir : Optional[str], optional nested directory to use for file storage, when None, data will be stored directly in __root, by default \"data\". When __root is file, subdirectory in __root parent directory will be used. Example ------- ``` >>> tmp = getfixture('tmp_path') >>> from magic_storage import StoreType >>> fs = FilesystemStorage(tmp) >>> example_item = {\"foo\": 32} >>> UID = \"EXAMPLE UID\" >>> fs.store_as(StoreType.JSON, uid=UID, item=example_item) '4c9e95de851b875493ba6c6dfb16b6aaae5c3e167aef9ab6edfeb0dbca2f6574' >>> fs.is_available(UID) True >>> fs.load_as(StoreType.JSON, uid=UID) {'foo': 32} >>> ``` \"\"\" def __init__ ( self , __root : str | Path , * , subdir : Optional [ str ] = \"data\" ) -> None : # store details about location in filesystem __root = Path ( __root ) # when __file__ is used, replace it with parent dir if __root . is_file (): __root = __root . parent if subdir is not None : self . _data_dir = __root / subdir else : self . _data_dir = __root self . _data_dir . mkdir ( 0o777 , True , True ) self . _cache : Optional [ RRCache ] = RRCache ( maxsize = 128 ) self . _encoding = \"utf-8\" super () . __init__ () def _filepath ( self , __uid : str ) -> Path : __uid = make_uid ( __uid ) assert isinstance ( __uid , str ) return self . _data_dir / __uid def _get_cache ( self ) -> Optional [ Cache ]: return self . _cache def _is_available ( self , __uid : str ) -> bool : fname = self . _filepath ( __uid ) return fname . exists () and fname . is_file () @cachedmethod ( _get_cache ) def _read_text ( self , uid : str ) -> str : with AtomicFile ( self . _filepath ( uid )) as file : return file . read_text ( encoding = self . _encoding ) @cachedmethod ( _get_cache ) def _read_bytes ( self , uid : str ) -> bytes : with AtomicFile ( self . _filepath ( uid )) as file : return file . read_bytes () def _write_text ( self , uid : str , item : str ) -> None : with AtomicFile ( self . _filepath ( uid )) as file : file . write_text ( item , encoding = self . _encoding ) def _write_bytes ( self , uid : str , item : bytes ) -> None : with AtomicFile ( self . _filepath ( uid )) as file : file . write_bytes ( item ) def _delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : self . _filepath ( __uid ) . unlink ( missing_ok ) def configure ( self , * , encoding : str | sentinel = sentinel , cache : Optional [ Cache ] | sentinel = sentinel , ) -> None : \"\"\"Configure FileStorage instance. Parameters ---------- encoding : str | sentinel, optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" cache : Optional[Cache] | sentinel, optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) \"\"\" if encoding is not sentinel : self . _encoding = encoding logging . debug ( f \"Changed encoding of FileStorage to { encoding } .\" ) if cache is not sentinel : self . _cache = cache # type: ignore logging . debug ( f \"Changed cache of FileStorage to { cache } .\" ) configure ( * , encoding = sentinel , cache = sentinel ) # Configure FileStorage instance. Parameters: Name Type Description Default encoding str | sentinel , optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" sentinel cache Optional [ Cache ] | sentinel , optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) sentinel Source code in magic_storage/impl/_filesystem.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def configure ( self , * , encoding : str | sentinel = sentinel , cache : Optional [ Cache ] | sentinel = sentinel , ) -> None : \"\"\"Configure FileStorage instance. Parameters ---------- encoding : str | sentinel, optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" cache : Optional[Cache] | sentinel, optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) \"\"\" if encoding is not sentinel : self . _encoding = encoding logging . debug ( f \"Changed encoding of FileStorage to { encoding } .\" ) if cache is not sentinel : self . _cache = cache # type: ignore logging . debug ( f \"Changed cache of FileStorage to { cache } .\" )","title":"FilesystemStorage"},{"location":"reference/filesystem_storage/#magic_storage.FilesystemStorage--example","text":"1 2 3 4 5 6 7 8 9 10 11 12 >>> tmp = getfixture('tmp_path') >>> from magic_storage import StoreType >>> fs = FilesystemStorage(tmp) >>> example_item = {\"foo\": 32} >>> UID = \"EXAMPLE UID\" >>> fs.store_as(StoreType.JSON, uid=UID, item=example_item) '4c9e95de851b875493ba6c6dfb16b6aaae5c3e167aef9ab6edfeb0dbca2f6574' >>> fs.is_available(UID) True >>> fs.load_as(StoreType.JSON, uid=UID) {'foo': 32} >>> Source code in magic_storage/impl/_filesystem.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 class FilesystemStorage ( StorageIOBase , FullyFeaturedMixin ): \"\"\"Implementation of storage class which operates on filesystem items to preserve saved items between sessions. Loading procedures can optionally use caching, they do by default, therefore without disabling it you can't rely on loads being always instantly up to date with stores. Encoding used to read text files, as well as cache can be changed using .configure() method. Parameters ---------- __root : str | Path root dir for fs storage, if __root points to file, parent directory of this file will be used. subdir : Optional[str], optional nested directory to use for file storage, when None, data will be stored directly in __root, by default \"data\". When __root is file, subdirectory in __root parent directory will be used. Example ------- ``` >>> tmp = getfixture('tmp_path') >>> from magic_storage import StoreType >>> fs = FilesystemStorage(tmp) >>> example_item = {\"foo\": 32} >>> UID = \"EXAMPLE UID\" >>> fs.store_as(StoreType.JSON, uid=UID, item=example_item) '4c9e95de851b875493ba6c6dfb16b6aaae5c3e167aef9ab6edfeb0dbca2f6574' >>> fs.is_available(UID) True >>> fs.load_as(StoreType.JSON, uid=UID) {'foo': 32} >>> ``` \"\"\" def __init__ ( self , __root : str | Path , * , subdir : Optional [ str ] = \"data\" ) -> None : # store details about location in filesystem __root = Path ( __root ) # when __file__ is used, replace it with parent dir if __root . is_file (): __root = __root . parent if subdir is not None : self . _data_dir = __root / subdir else : self . _data_dir = __root self . _data_dir . mkdir ( 0o777 , True , True ) self . _cache : Optional [ RRCache ] = RRCache ( maxsize = 128 ) self . _encoding = \"utf-8\" super () . __init__ () def _filepath ( self , __uid : str ) -> Path : __uid = make_uid ( __uid ) assert isinstance ( __uid , str ) return self . _data_dir / __uid def _get_cache ( self ) -> Optional [ Cache ]: return self . _cache def _is_available ( self , __uid : str ) -> bool : fname = self . _filepath ( __uid ) return fname . exists () and fname . is_file () @cachedmethod ( _get_cache ) def _read_text ( self , uid : str ) -> str : with AtomicFile ( self . _filepath ( uid )) as file : return file . read_text ( encoding = self . _encoding ) @cachedmethod ( _get_cache ) def _read_bytes ( self , uid : str ) -> bytes : with AtomicFile ( self . _filepath ( uid )) as file : return file . read_bytes () def _write_text ( self , uid : str , item : str ) -> None : with AtomicFile ( self . _filepath ( uid )) as file : file . write_text ( item , encoding = self . _encoding ) def _write_bytes ( self , uid : str , item : bytes ) -> None : with AtomicFile ( self . _filepath ( uid )) as file : file . write_bytes ( item ) def _delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : self . _filepath ( __uid ) . unlink ( missing_ok ) def configure ( self , * , encoding : str | sentinel = sentinel , cache : Optional [ Cache ] | sentinel = sentinel , ) -> None : \"\"\"Configure FileStorage instance. Parameters ---------- encoding : str | sentinel, optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" cache : Optional[Cache] | sentinel, optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) \"\"\" if encoding is not sentinel : self . _encoding = encoding logging . debug ( f \"Changed encoding of FileStorage to { encoding } .\" ) if cache is not sentinel : self . _cache = cache # type: ignore logging . debug ( f \"Changed cache of FileStorage to { cache } .\" )","title":"Example"},{"location":"reference/filesystem_storage/#magic_storage.impl._filesystem.FilesystemStorage.configure","text":"Configure FileStorage instance. Parameters: Name Type Description Default encoding str | sentinel , optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" sentinel cache Optional [ Cache ] | sentinel , optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) sentinel Source code in magic_storage/impl/_filesystem.py 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 def configure ( self , * , encoding : str | sentinel = sentinel , cache : Optional [ Cache ] | sentinel = sentinel , ) -> None : \"\"\"Configure FileStorage instance. Parameters ---------- encoding : str | sentinel, optional Change encoding used to read/write text, when sentinel, old value is kept, by default \"utf-8\" cache : Optional[Cache] | sentinel, optional Change cache instance used for caching, set to None to disable caching, when sentinel, old value is kept, by default RRCache(maxsize=128) \"\"\" if encoding is not sentinel : self . _encoding = encoding logging . debug ( f \"Changed encoding of FileStorage to { encoding } .\" ) if cache is not sentinel : self . _cache = cache # type: ignore logging . debug ( f \"Changed cache of FileStorage to { cache } .\" )","title":"configure()"},{"location":"reference/in_memory_storage/","text":"Bases: StorageIOBase , FullyFeaturedMixin Implementation of storage class which operates only in RAM and thus will be lost after garbage collection. However it is much faster than any other cache type. Source code in magic_storage/impl/_memory.py 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class InMemoryStorage ( StorageIOBase , FullyFeaturedMixin ): \"\"\"Implementation of storage class which operates only in RAM and thus will be lost after garbage collection. However it is much faster than any other cache type. \"\"\" def __init__ ( self ) -> None : super () . __init__ () self . __storage : dict [ str , str | bytes ] = {} def _is_available ( self , uid : str ) -> bool : return uid in self . __storage def _read_text ( self , uid : str ) -> str : value = self . __storage [ uid ] assert isinstance ( value , str ) return value def _read_bytes ( self , uid : str ) -> bytes : value = self . __storage [ uid ] assert isinstance ( value , bytes ) return value def _write_text ( self , uid : str , item : str ) -> None : self . __storage [ uid ] = item def _write_bytes ( self , uid : str , item : bytes ) -> None : self . __storage [ uid ] = item def _delete ( self , __uid : str , / , * , missing_ok : bool = False ) -> None : if missing_ok : self . __storage . pop ( __uid , None ) else : self . __storage . pop ( __uid )","title":"InMemoryStorage"},{"location":"reference/magic_storage/","text":"This class instantiated and caches loaders which can be acquired with dedicated methods. Resource storages are neither guaranteed to be cached, nor to be always newly created. Source code in magic_storage/_magic.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class MagicStorage : \"\"\"This class instantiated and caches loaders which can be acquired with dedicated methods. Resource storages are neither guaranteed to be cached, nor to be always newly created. \"\"\" def filesystem ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" return FilesystemStorage ( __root ) def filesystem_no_cache ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to not use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" fs = FilesystemStorage ( __root ) fs . configure ( cache = None ) return fs filesystem ( __root ) # Return local cache storage for current file. This object will be configured to use cache. Parameters: Name Type Description Default current_file str Either directory or file, when file, its parent directory will be used. required Returns: Type Description FilesystemStorage new storage object. Source code in magic_storage/_magic.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def filesystem ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" return FilesystemStorage ( __root ) filesystem_no_cache ( __root ) # Return local cache storage for current file. This object will be configured to not use cache. Parameters: Name Type Description Default current_file str Either directory or file, when file, its parent directory will be used. required Returns: Type Description FilesystemStorage new storage object. Source code in magic_storage/_magic.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def filesystem_no_cache ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to not use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" fs = FilesystemStorage ( __root ) fs . configure ( cache = None ) return fs","title":"MagicStorage"},{"location":"reference/magic_storage/#magic_storage._magic.MagicStorage.filesystem","text":"Return local cache storage for current file. This object will be configured to use cache. Parameters: Name Type Description Default current_file str Either directory or file, when file, its parent directory will be used. required Returns: Type Description FilesystemStorage new storage object. Source code in magic_storage/_magic.py 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 def filesystem ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" return FilesystemStorage ( __root )","title":"filesystem()"},{"location":"reference/magic_storage/#magic_storage._magic.MagicStorage.filesystem_no_cache","text":"Return local cache storage for current file. This object will be configured to not use cache. Parameters: Name Type Description Default current_file str Either directory or file, when file, its parent directory will be used. required Returns: Type Description FilesystemStorage new storage object. Source code in magic_storage/_magic.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def filesystem_no_cache ( self , __root : str | Path ) -> FilesystemStorage : \"\"\"Return local cache storage for current file. This object will be configured to not use cache. Parameters ---------- current_file : str Either directory or file, when file, its parent directory will be used. Returns ------- FilesystemStorage new storage object. \"\"\" fs = FilesystemStorage ( __root ) fs . configure ( cache = None ) return fs","title":"filesystem_no_cache()"},{"location":"reference/mixins/","text":"Bases: CacheIfMissingMixin Mixin class which aggregates all mixins from magic_storage.mixins submodule. Source code in magic_storage/mixins/__init__.py 8 9 10 class FullyFeaturedMixin ( CacheIfMissingMixin ): \"\"\"Mixin class which aggregates all mixins from magic_storage.mixins submodule.\"\"\" Bases: ABC Source code in magic_storage/mixins/_cache_if_missing.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 class CacheIfMissingMixin ( ABC ): @abstractmethod def is_available ( self , __uid : str , / ) -> bool : ... @abstractmethod def load_as ( # noqa: FNE004 self , store_type : StoreType , uid : str , ** load_kw : Any , ) -> Any : ... @abstractmethod def store_as ( self , store_type : StoreType , / , uid : str , item : Any , ** dump_kw : Any , ) -> str : ... def cache_if_missing ( self , uid : str , callback : Callable [[], _R ], store_type : StoreType = StoreType . PICKLE , ) -> _R : \"\"\"Store and return object if not present in cache, otherwise load from cache and return. In case of load failure object cache is recreated. Parameters ---------- uid : str Object identifier used to find object in cache. callback : Callable[[], _R] Callback function which can create new object if object is not found in cache store_type : StoreType, optional Determines how object should be stored in cache, by default StoreType.PICKLE Returns ------- _R Object loaded from cache OR object created with callback and stored to cache. \"\"\" uid = make_uid ( uid ) if self . is_available ( uid ): logging . debug ( f \"' { uid } ' is available and will be loaded.\" ) try : return self . load_as ( store_type , uid = uid ) # type: ignore except Exception as e : logging . exception ( e ) logging . warning ( f \"Failed to load ' { uid } ' due to loading error. Cache will be recreated.\" ) else : logging . debug ( f \"Resource ' { uid } ' is NOT available thus will be created.\" ) # If cache is not present OR if cache load failed item = callback () self . store_as ( store_type , uid = uid , item = item ) return item # type: ignore cache_if_missing ( uid , callback , store_type = StoreType . PICKLE ) # Store and return object if not present in cache, otherwise load from cache and return. In case of load failure object cache is recreated. Parameters: Name Type Description Default uid str Object identifier used to find object in cache. required callback Callable [[], _R ] Callback function which can create new object if object is not found in cache required store_type StoreType , optional Determines how object should be stored in cache, by default StoreType.PICKLE StoreType.PICKLE Returns: Type Description _R Object loaded from cache OR object created with callback and stored to cache. Source code in magic_storage/mixins/_cache_if_missing.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def cache_if_missing ( self , uid : str , callback : Callable [[], _R ], store_type : StoreType = StoreType . PICKLE , ) -> _R : \"\"\"Store and return object if not present in cache, otherwise load from cache and return. In case of load failure object cache is recreated. Parameters ---------- uid : str Object identifier used to find object in cache. callback : Callable[[], _R] Callback function which can create new object if object is not found in cache store_type : StoreType, optional Determines how object should be stored in cache, by default StoreType.PICKLE Returns ------- _R Object loaded from cache OR object created with callback and stored to cache. \"\"\" uid = make_uid ( uid ) if self . is_available ( uid ): logging . debug ( f \"' { uid } ' is available and will be loaded.\" ) try : return self . load_as ( store_type , uid = uid ) # type: ignore except Exception as e : logging . exception ( e ) logging . warning ( f \"Failed to load ' { uid } ' due to loading error. Cache will be recreated.\" ) else : logging . debug ( f \"Resource ' { uid } ' is NOT available thus will be created.\" ) # If cache is not present OR if cache load failed item = callback () self . store_as ( store_type , uid = uid , item = item ) return item # type: ignore","title":"Mixins"},{"location":"reference/mixins/#magic_storage.mixins._cache_if_missing.CacheIfMissingMixin.cache_if_missing","text":"Store and return object if not present in cache, otherwise load from cache and return. In case of load failure object cache is recreated. Parameters: Name Type Description Default uid str Object identifier used to find object in cache. required callback Callable [[], _R ] Callback function which can create new object if object is not found in cache required store_type StoreType , optional Determines how object should be stored in cache, by default StoreType.PICKLE StoreType.PICKLE Returns: Type Description _R Object loaded from cache OR object created with callback and stored to cache. Source code in magic_storage/mixins/_cache_if_missing.py 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def cache_if_missing ( self , uid : str , callback : Callable [[], _R ], store_type : StoreType = StoreType . PICKLE , ) -> _R : \"\"\"Store and return object if not present in cache, otherwise load from cache and return. In case of load failure object cache is recreated. Parameters ---------- uid : str Object identifier used to find object in cache. callback : Callable[[], _R] Callback function which can create new object if object is not found in cache store_type : StoreType, optional Determines how object should be stored in cache, by default StoreType.PICKLE Returns ------- _R Object loaded from cache OR object created with callback and stored to cache. \"\"\" uid = make_uid ( uid ) if self . is_available ( uid ): logging . debug ( f \"' { uid } ' is available and will be loaded.\" ) try : return self . load_as ( store_type , uid = uid ) # type: ignore except Exception as e : logging . exception ( e ) logging . warning ( f \"Failed to load ' { uid } ' due to loading error. Cache will be recreated.\" ) else : logging . debug ( f \"Resource ' { uid } ' is NOT available thus will be created.\" ) # If cache is not present OR if cache load failed item = callback () self . store_as ( store_type , uid = uid , item = item ) return item # type: ignore","title":"cache_if_missing()"},{"location":"reference/reader_base/","text":"Bases: ABC Source code in magic_storage/base/_reader.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 class ReaderBase ( ABC ): def is_available ( self , __uid : str , / ) -> bool : \"\"\"Check if object with specified identifier and store type is present in cache. Parameters ---------- uid : str object unique identifier. Returns ------- bool True when object is present, False otherwise. Examples -------- ``` >>> ReaderExampleImpl().is_available(\"example1\") True >>> ReaderExampleImpl().is_available(\"not available\") False >>> ``` \"\"\" __uid = make_uid ( __uid ) assert isinstance ( __uid , str ), __uid status = self . _is_available ( __uid ) logging . debug ( f \"Availability status of { __uid } is { status } .\" ) return status @abstractmethod def _is_available ( self , __uid : str , / ) -> bool : ... def load_as ( # noqa: FNE004 self , store_type : StoreType , uid : str , ** load_kw : Any , ) -> Any : \"\"\"Load object from cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType, optional store type from enum. uid : str object unique identifier. Returns ------- str Loaded object. Examples -------- ``` >>> ReaderExampleImpl().load_as(StoreType.TEXT, uid=\"example1\") '{\"foo\": 32}' >>> ReaderExampleImpl().load_as(StoreType.PICKLE, uid=\"example2\") {'foo': 32} >>> ``` \"\"\" return self . _load_as ( store_type , uid = uid , ** load_kw ) def _load_as ( # noqa: FNE004 self , store_type : StoreType , / , * , uid : str , ** load_kw : Any , ) -> Any : uid = make_uid ( uid ) assert isinstance ( uid , str ), uid logging . debug ( f \"Loading ' { uid } ' as { store_type } .\" ) # We can't check if retval is not None as anything can be stored, including None retval = self . _LOAD_MAP [ store_type ]( self , uid , ** load_kw ) logging . debug ( f \"Successfully loaded { uid } as { store_type } \" ) return retval def _load_text ( self , uid : str ) -> str : # noqa: FNE004 value = self . _read_text ( uid ) assert isinstance ( value , str ) return value @abstractmethod def _read_text ( self , __uid : str , / ) -> str : ... def _load_json ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 raw_value = self . _read_text ( uid ) assert isinstance ( raw_value , str ) value = json . loads ( raw_value , ** load_kw ) return value def _load_bytes ( self , uid : str ) -> bytes : # noqa: FNE004 value = self . _read_bytes ( uid ) assert isinstance ( value , bytes ), value return value @abstractmethod def _read_bytes ( self , __uid : str , / ) -> bytes : ... def _load_pickle ( # noqa: FNE004 self , uid : str , ** pickle_load_kw : Any ) -> Any : source = self . _read_bytes ( uid ) assert isinstance ( source , bytes ) source = decompress ( source ) assert isinstance ( source , bytes ) ob = pickle . loads ( source , ** pickle_load_kw ) return ob def load_text ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as text. This is only suitable for str and str-like objects. Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. Returns ------- str Loaded object. \"\"\" return self . _load_as ( StoreType . TEXT , uid = uid , ** load_kw ) def load_bytes ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as binary. This is only suitable for bytes and bytes-like objects. Parameters ---------- uid : str object unique identifier. Returns ------- bytes Loaded object. \"\"\" return self . _load_as ( StoreType . BINARY , uid = uid , ** load_kw ) def load_json ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as json. This can be used with any object which can be decoded with json.loads() Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. **load_kw: Any keyword argument passed to json.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . JSON , uid = uid , ** load_kw ) def load_pickle ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as pickle. This can be used with any object which can be decoded with pickle.loads() Parameters ---------- uid : str object unique identifier. **load_kw: Any keyword argument passed to pickle.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . PICKLE , uid = uid , ** load_kw ) _LOAD_MAP : dict [ StoreType , Callable [[ ReaderBase , str ], Any ]] = { StoreType . TEXT : _load_text , StoreType . BINARY : _load_bytes , StoreType . JSON : _load_json , StoreType . PICKLE : _load_pickle , } is_available ( __uid ) # Check if object with specified identifier and store type is present in cache. Parameters: Name Type Description Default uid str object unique identifier. required Returns: Type Description bool True when object is present, False otherwise. Examples: 1 2 3 4 5 >>> ReaderExampleImpl().is_available(\"example1\") True >>> ReaderExampleImpl().is_available(\"not available\") False >>> Source code in magic_storage/base/_reader.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def is_available ( self , __uid : str , / ) -> bool : \"\"\"Check if object with specified identifier and store type is present in cache. Parameters ---------- uid : str object unique identifier. Returns ------- bool True when object is present, False otherwise. Examples -------- ``` >>> ReaderExampleImpl().is_available(\"example1\") True >>> ReaderExampleImpl().is_available(\"not available\") False >>> ``` \"\"\" __uid = make_uid ( __uid ) assert isinstance ( __uid , str ), __uid status = self . _is_available ( __uid ) logging . debug ( f \"Availability status of { __uid } is { status } .\" ) return status load_as ( store_type , uid , ** load_kw ) # Load object from cache in format selected by parameter store_as. Parameters: Name Type Description Default store_type StoreType , optional store type from enum. required uid str object unique identifier. required Returns: Type Description str Loaded object. Examples: 1 2 3 4 5 >>> ReaderExampleImpl().load_as(StoreType.TEXT, uid=\"example1\") '{\"foo\": 32}' >>> ReaderExampleImpl().load_as(StoreType.PICKLE, uid=\"example2\") {'foo': 32} >>> Source code in magic_storage/base/_reader.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def load_as ( # noqa: FNE004 self , store_type : StoreType , uid : str , ** load_kw : Any , ) -> Any : \"\"\"Load object from cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType, optional store type from enum. uid : str object unique identifier. Returns ------- str Loaded object. Examples -------- ``` >>> ReaderExampleImpl().load_as(StoreType.TEXT, uid=\"example1\") '{\"foo\": 32}' >>> ReaderExampleImpl().load_as(StoreType.PICKLE, uid=\"example2\") {'foo': 32} >>> ``` \"\"\" return self . _load_as ( store_type , uid = uid , ** load_kw ) load_bytes ( uid , ** load_kw ) # Load object with specified identifier as binary. This is only suitable for bytes and bytes-like objects. Parameters: Name Type Description Default uid str object unique identifier. required Returns: Type Description bytes Loaded object. Source code in magic_storage/base/_reader.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def load_bytes ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as binary. This is only suitable for bytes and bytes-like objects. Parameters ---------- uid : str object unique identifier. Returns ------- bytes Loaded object. \"\"\" return self . _load_as ( StoreType . BINARY , uid = uid , ** load_kw ) load_json ( uid , ** load_kw ) # Load object with specified identifier as json. This can be used with any object which can be decoded with json.loads() Parameters: Name Type Description Default uid str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. required **load_kw Any keyword argument passed to json.loads(). {} Returns: Type Description Any Loaded object. Source code in magic_storage/base/_reader.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def load_json ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as json. This can be used with any object which can be decoded with json.loads() Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. **load_kw: Any keyword argument passed to json.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . JSON , uid = uid , ** load_kw ) load_pickle ( uid , ** load_kw ) # Load object with specified identifier as pickle. This can be used with any object which can be decoded with pickle.loads() Parameters: Name Type Description Default uid str object unique identifier. required **load_kw Any keyword argument passed to pickle.loads(). {} Returns: Type Description Any Loaded object. Source code in magic_storage/base/_reader.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 def load_pickle ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as pickle. This can be used with any object which can be decoded with pickle.loads() Parameters ---------- uid : str object unique identifier. **load_kw: Any keyword argument passed to pickle.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . PICKLE , uid = uid , ** load_kw ) load_text ( uid , ** load_kw ) # Load object with specified identifier as text. This is only suitable for str and str-like objects. Parameters: Name Type Description Default uid str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. required Returns: Type Description str Loaded object. Source code in magic_storage/base/_reader.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def load_text ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as text. This is only suitable for str and str-like objects. Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. Returns ------- str Loaded object. \"\"\" return self . _load_as ( StoreType . TEXT , uid = uid , ** load_kw )","title":"ReaderBase"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.is_available","text":"Check if object with specified identifier and store type is present in cache. Parameters: Name Type Description Default uid str object unique identifier. required Returns: Type Description bool True when object is present, False otherwise. Examples: 1 2 3 4 5 >>> ReaderExampleImpl().is_available(\"example1\") True >>> ReaderExampleImpl().is_available(\"not available\") False >>> Source code in magic_storage/base/_reader.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def is_available ( self , __uid : str , / ) -> bool : \"\"\"Check if object with specified identifier and store type is present in cache. Parameters ---------- uid : str object unique identifier. Returns ------- bool True when object is present, False otherwise. Examples -------- ``` >>> ReaderExampleImpl().is_available(\"example1\") True >>> ReaderExampleImpl().is_available(\"not available\") False >>> ``` \"\"\" __uid = make_uid ( __uid ) assert isinstance ( __uid , str ), __uid status = self . _is_available ( __uid ) logging . debug ( f \"Availability status of { __uid } is { status } .\" ) return status","title":"is_available()"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.load_as","text":"Load object from cache in format selected by parameter store_as. Parameters: Name Type Description Default store_type StoreType , optional store type from enum. required uid str object unique identifier. required Returns: Type Description str Loaded object. Examples: 1 2 3 4 5 >>> ReaderExampleImpl().load_as(StoreType.TEXT, uid=\"example1\") '{\"foo\": 32}' >>> ReaderExampleImpl().load_as(StoreType.PICKLE, uid=\"example2\") {'foo': 32} >>> Source code in magic_storage/base/_reader.py 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 def load_as ( # noqa: FNE004 self , store_type : StoreType , uid : str , ** load_kw : Any , ) -> Any : \"\"\"Load object from cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType, optional store type from enum. uid : str object unique identifier. Returns ------- str Loaded object. Examples -------- ``` >>> ReaderExampleImpl().load_as(StoreType.TEXT, uid=\"example1\") '{\"foo\": 32}' >>> ReaderExampleImpl().load_as(StoreType.PICKLE, uid=\"example2\") {'foo': 32} >>> ``` \"\"\" return self . _load_as ( store_type , uid = uid , ** load_kw )","title":"load_as()"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.load_bytes","text":"Load object with specified identifier as binary. This is only suitable for bytes and bytes-like objects. Parameters: Name Type Description Default uid str object unique identifier. required Returns: Type Description bytes Loaded object. Source code in magic_storage/base/_reader.py 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def load_bytes ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as binary. This is only suitable for bytes and bytes-like objects. Parameters ---------- uid : str object unique identifier. Returns ------- bytes Loaded object. \"\"\" return self . _load_as ( StoreType . BINARY , uid = uid , ** load_kw )","title":"load_bytes()"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.load_json","text":"Load object with specified identifier as json. This can be used with any object which can be decoded with json.loads() Parameters: Name Type Description Default uid str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. required **load_kw Any keyword argument passed to json.loads(). {} Returns: Type Description Any Loaded object. Source code in magic_storage/base/_reader.py 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 def load_json ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as json. This can be used with any object which can be decoded with json.loads() Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. **load_kw: Any keyword argument passed to json.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . JSON , uid = uid , ** load_kw )","title":"load_json()"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.load_pickle","text":"Load object with specified identifier as pickle. This can be used with any object which can be decoded with pickle.loads() Parameters: Name Type Description Default uid str object unique identifier. required **load_kw Any keyword argument passed to pickle.loads(). {} Returns: Type Description Any Loaded object. Source code in magic_storage/base/_reader.py 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 def load_pickle ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as pickle. This can be used with any object which can be decoded with pickle.loads() Parameters ---------- uid : str object unique identifier. **load_kw: Any keyword argument passed to pickle.loads(). Returns ------- Any Loaded object. \"\"\" return self . _load_as ( StoreType . PICKLE , uid = uid , ** load_kw )","title":"load_pickle()"},{"location":"reference/reader_base/#magic_storage.base._reader.ReaderBase.load_text","text":"Load object with specified identifier as text. This is only suitable for str and str-like objects. Parameters: Name Type Description Default uid str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. required Returns: Type Description str Loaded object. Source code in magic_storage/base/_reader.py 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 def load_text ( self , uid : str , ** load_kw : Any ) -> Any : # noqa: FNE004 \"\"\"Load object with specified identifier as text. This is only suitable for str and str-like objects. Parameters ---------- uid : str object unique identifier. Only Alphanumeric characters are allowed, other are replaced with '_'. Returns ------- str Loaded object. \"\"\" return self . _load_as ( StoreType . TEXT , uid = uid , ** load_kw )","title":"load_text()"},{"location":"reference/storage_io_base/","text":"Bases: ReaderBase , WriterBase , DeleterBase Source code in magic_storage/base/_storage_io.py 10 11 12 class StorageIOBase ( ReaderBase , WriterBase , DeleterBase ): def configure ( self ) -> None : \"\"\"Configure resource storage access.\"\"\" configure () # Configure resource storage access. Source code in magic_storage/base/_storage_io.py 11 12 def configure ( self ) -> None : \"\"\"Configure resource storage access.\"\"\"","title":"StorageIOBase"},{"location":"reference/storage_io_base/#magic_storage.base._storage_io.StorageIOBase.configure","text":"Configure resource storage access. Source code in magic_storage/base/_storage_io.py 11 12 def configure ( self ) -> None : \"\"\"Configure resource storage access.\"\"\"","title":"configure()"},{"location":"reference/store_type/","text":"Bases: Enum Source code in magic_storage/_store_type.py 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 class StoreType ( Enum ): # basic storage type TEXT = TEXT_BIT BINARY = BYTES_BIT # complex storage type JSON = ( TEXT_BIT | SUPPORT_LIST_BIT | SUPPORT_TUPLE_BIT | SUPPORT_DICT_BIT | SUPPORT_STR_BIT | JSON_BIT ) PICKLE = BYTES_BIT | SUPPORT_ANY_BIT | PICKLE_BIT def __str__ ( self ) -> str : return self . name def __repr__ ( self ) -> str : return f \" { self . name } : { self . value : >08b } \" def is_text ( self ) -> bool : return bool ( self . value & TEXT_BIT ) def is_binary ( self ) -> bool : # pragma: no cover return bool ( self . value & BYTES_BIT ) @classmethod def iter_text ( cls ) -> Iterable [ StoreType ]: return filter ( lambda e : e . is_text (), cls ) @classmethod def iter_binary ( cls ) -> Iterable [ StoreType ]: # pragma: no cover return filter ( lambda e : e . is_binary (), cls )","title":"StoreType Enum"},{"location":"reference/writer_base/","text":"Bases: ABC Source code in magic_storage/base/_writer.py 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 class WriterBase ( ABC ): def store_as ( self , store_type : StoreType , / , uid : str , item : Any , ** dump_kw : Any , ) -> str : \"\"\"Dump object to cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType store type from enum uid : str object unique identifier. item : Any item to store, constraints depend on storage type. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( store_type , uid = uid , item = item , ** dump_kw ) def _store_as ( self , store_type : StoreType , / , * , uid : str , item : Any , ** dump_kw : Any , ) -> str : uid = make_uid ( uid ) assert isinstance ( uid , str ), uid logging . debug ( f \"Dumping ' { uid } ' as { store_type } .\" ) retval = self . _STORE_MAP [ store_type ]( self , uid , item , ** dump_kw ) assert retval is None , retval logging . debug ( f \"Successfully dumped { uid } as { store_type } \" ) return uid def _store_text ( self , uid : str , item : Any , ** str_kw : Any ) -> None : raw_value = str ( item , ** str_kw ) assert isinstance ( raw_value , str ), raw_value retval = self . _write_text ( uid , raw_value ) assert retval is None , retval return retval @abstractmethod def _write_text ( self , __uid : str , __item : str , / ) -> None : ... def _store_json ( self , uid : str , item : Any , ** json_dumps_kw : Any ) -> None : try : raw_value = json . dumps ( item , ** json_dumps_kw ) except TypeError : if hasattr ( item , \"json\" ) and callable ( item . json ): raw_value = item . json () else : raise assert isinstance ( raw_value , str ), raw_value retval = self . _write_text ( uid , raw_value ) assert retval is None , retval return retval def _store_bytes ( self , uid : str , item : Any , ** bytes_kw : Any ) -> None : raw_value = bytes ( item , ** bytes_kw ) assert isinstance ( raw_value , bytes ), raw_value retval = self . _write_bytes ( uid , raw_value ) assert retval is None , retval logging . debug ( f \"Successfully dumped { uid } as BYTES\" ) return retval @abstractmethod def _write_bytes ( self , __uid : str , __item : bytes , / ) -> None : ... def _store_pickle ( self , uid : str , item : Any , ** pickle_dump_kw : Any ) -> None : raw_value = pickle . dumps ( item , ** pickle_dump_kw ) assert isinstance ( raw_value , bytes ) raw_value = compress ( raw_value ) assert isinstance ( raw_value , bytes ), raw_value retval = self . _write_bytes ( uid , raw_value ) assert retval is None , retval logging . debug ( f \"Successfully dumped { uid } as PICKLE\" ) return retval def store_str ( self , uid : str , item : str , ** str_kw : Any ) -> str : \"\"\"Dump object to cache in form of text. Parameters ---------- uid : str object unique identifier. item : str item to store, str or str-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . TEXT , uid = uid , item = item , ** str_kw ) def store_bytes ( self , uid : str , item : bytes , ** bytes_kw : Any ) -> str : \"\"\"Dump object to cache in form of binary. Parameters ---------- uid : str object unique identifier. item : str item to store, bytes or bytes-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . BINARY , uid = uid , item = item , ** bytes_kw ) def store_json ( self , uid : str , item : Any , ** json_dumps_kw : Any ) -> str : \"\"\"Dump object to cache in form of json encoded text. Parameters ---------- uid : str object unique identifier. item : str item to store, any object which can be encoded with json.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . JSON , uid = uid , item = item , ** json_dumps_kw ) def store_pickle ( self , uid : str , item : Any , ** pickle_dump_kw : Any ) -> str : \"\"\"Dump object to cache in form of pickled binary. Because pickle is a binary format, it is always compressed with lzma algorithm. Parameters ---------- identifier : str object unique identifier. item : str item to store, any object which can be encoded with pickle.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . PICKLE , uid = uid , item = item , ** pickle_dump_kw ) _STORE_MAP : dict [ StoreType , Callable [[ WriterBase , str , Any ], None ]] = { StoreType . TEXT : _store_text , StoreType . BINARY : _store_bytes , StoreType . JSON : _store_json , StoreType . PICKLE : _store_pickle , } store_as ( store_type , / , uid , item , ** dump_kw ) # Dump object to cache in format selected by parameter store_as. Parameters: Name Type Description Default store_type StoreType store type from enum required uid str object unique identifier. required item Any item to store, constraints depend on storage type. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def store_as ( self , store_type : StoreType , / , uid : str , item : Any , ** dump_kw : Any , ) -> str : \"\"\"Dump object to cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType store type from enum uid : str object unique identifier. item : Any item to store, constraints depend on storage type. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( store_type , uid = uid , item = item , ** dump_kw ) store_bytes ( uid , item , ** bytes_kw ) # Dump object to cache in form of binary. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, bytes or bytes-like objects. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def store_bytes ( self , uid : str , item : bytes , ** bytes_kw : Any ) -> str : \"\"\"Dump object to cache in form of binary. Parameters ---------- uid : str object unique identifier. item : str item to store, bytes or bytes-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . BINARY , uid = uid , item = item , ** bytes_kw ) store_json ( uid , item , ** json_dumps_kw ) # Dump object to cache in form of json encoded text. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, any object which can be encoded with json.dumps(). required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def store_json ( self , uid : str , item : Any , ** json_dumps_kw : Any ) -> str : \"\"\"Dump object to cache in form of json encoded text. Parameters ---------- uid : str object unique identifier. item : str item to store, any object which can be encoded with json.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . JSON , uid = uid , item = item , ** json_dumps_kw ) store_pickle ( uid , item , ** pickle_dump_kw ) # Dump object to cache in form of pickled binary. Because pickle is a binary format, it is always compressed with lzma algorithm. Parameters: Name Type Description Default identifier str object unique identifier. required item str item to store, any object which can be encoded with pickle.dumps(). required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def store_pickle ( self , uid : str , item : Any , ** pickle_dump_kw : Any ) -> str : \"\"\"Dump object to cache in form of pickled binary. Because pickle is a binary format, it is always compressed with lzma algorithm. Parameters ---------- identifier : str object unique identifier. item : str item to store, any object which can be encoded with pickle.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . PICKLE , uid = uid , item = item , ** pickle_dump_kw ) store_str ( uid , item , ** str_kw ) # Dump object to cache in form of text. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, str or str-like objects. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def store_str ( self , uid : str , item : str , ** str_kw : Any ) -> str : \"\"\"Dump object to cache in form of text. Parameters ---------- uid : str object unique identifier. item : str item to store, str or str-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . TEXT , uid = uid , item = item , ** str_kw )","title":"WriterBase"},{"location":"reference/writer_base/#magic_storage.base._writer.WriterBase.store_as","text":"Dump object to cache in format selected by parameter store_as. Parameters: Name Type Description Default store_type StoreType store type from enum required uid str object unique identifier. required item Any item to store, constraints depend on storage type. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def store_as ( self , store_type : StoreType , / , uid : str , item : Any , ** dump_kw : Any , ) -> str : \"\"\"Dump object to cache in format selected by parameter store_as. Parameters ---------- store_type : StoreType store type from enum uid : str object unique identifier. item : Any item to store, constraints depend on storage type. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( store_type , uid = uid , item = item , ** dump_kw )","title":"store_as()"},{"location":"reference/writer_base/#magic_storage.base._writer.WriterBase.store_bytes","text":"Dump object to cache in form of binary. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, bytes or bytes-like objects. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 def store_bytes ( self , uid : str , item : bytes , ** bytes_kw : Any ) -> str : \"\"\"Dump object to cache in form of binary. Parameters ---------- uid : str object unique identifier. item : str item to store, bytes or bytes-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . BINARY , uid = uid , item = item , ** bytes_kw )","title":"store_bytes()"},{"location":"reference/writer_base/#magic_storage.base._writer.WriterBase.store_json","text":"Dump object to cache in form of json encoded text. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, any object which can be encoded with json.dumps(). required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 def store_json ( self , uid : str , item : Any , ** json_dumps_kw : Any ) -> str : \"\"\"Dump object to cache in form of json encoded text. Parameters ---------- uid : str object unique identifier. item : str item to store, any object which can be encoded with json.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . JSON , uid = uid , item = item , ** json_dumps_kw )","title":"store_json()"},{"location":"reference/writer_base/#magic_storage.base._writer.WriterBase.store_pickle","text":"Dump object to cache in form of pickled binary. Because pickle is a binary format, it is always compressed with lzma algorithm. Parameters: Name Type Description Default identifier str object unique identifier. required item str item to store, any object which can be encoded with pickle.dumps(). required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 def store_pickle ( self , uid : str , item : Any , ** pickle_dump_kw : Any ) -> str : \"\"\"Dump object to cache in form of pickled binary. Because pickle is a binary format, it is always compressed with lzma algorithm. Parameters ---------- identifier : str object unique identifier. item : str item to store, any object which can be encoded with pickle.dumps(). Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . PICKLE , uid = uid , item = item , ** pickle_dump_kw )","title":"store_pickle()"},{"location":"reference/writer_base/#magic_storage.base._writer.WriterBase.store_str","text":"Dump object to cache in form of text. Parameters: Name Type Description Default uid str object unique identifier. required item str item to store, str or str-like objects. required Returns: Type Description str Identifier after cleanup and tagging (real used identifier). Source code in magic_storage/base/_writer.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def store_str ( self , uid : str , item : str , ** str_kw : Any ) -> str : \"\"\"Dump object to cache in form of text. Parameters ---------- uid : str object unique identifier. item : str item to store, str or str-like objects. Returns ------- str Identifier after cleanup and tagging (real used identifier). \"\"\" return self . _store_as ( StoreType . TEXT , uid = uid , item = item , ** str_kw )","title":"store_str()"}]}